# 1. Vector DB란?

정보는 다양한 형태로 제공 됨 

예를 들면, 텍스트 문서, 리치 미디어, 오디오와 같이 비정형 정보도 있고 
애플리케이션 로그, 테이블, 그래프와 같이 정형화된 정보가 있음 

인공 지능과 기계 학습(AI/ML)을 통해 일종의 ML 모델인 임베딩 모델을 만들 수 있는데, 
임베딩은 모든 유형의 데이터의 의미와 컨텍스트(=맥락)를 캡처하는 벡터로 인코딩하는 과정임
이를 통해 인접한 데이터 포인트를 검색하여 유사한 정보를 찾을 수 있음
예시로 벡터 검색 방법을 사용하면 스마트폰으로 사진을 찍고 비슷한 이미지를 검색하는 등 고유한 경험을 할 수 있음

**벡터 데이터베이스는 벡터를 고차원(=N차원) 포인트로 저장하고 검색하는 기능을 제공하며, 
N차원 공간에서 가장 가까운 이웃을 효율적이고 빠르게 조회할 수 있는 기능을 활용** 

![image](https://github.com/user-attachments/assets/fb26d956-8ebd-488f-8cec-6aaa923da0f8)


- Vector DB의 파이프라인

<span style="color: red">
**조회 기능으로는 일반적으로 k-NN(k-Nearest Neighbor) 인덱스로 구동되며 “HNSW 및 IVF”와 
같은 알고리즘으로 구축**
</span>


<details>
<summary>HNSW 알고리즘</summary>


https://velog.io/@eenzeenee/neural-search-HNSW-알고리즘-설명

그래프, 네트워크를 기반으로 이동하며 가장 가까운 검색 대상을 찾아내는 알고리즘 이때, 계층을 쌓아 점차 밀도가 높아지는 레이어로 이동하며 검색 대상과 가장 가까운 곳으로 이동

![image](https://github.com/user-attachments/assets/1c35c482-1949-4f53-afb8-de2add1c93a9)

</details>

<details>
<summary>IVF 알고리즘</summary>


https://medium.com/rate-labs/milvus-벡터-데이터베이스-b26065c51c16

IVF(Inverted File Index)는 유사한 벡터 데이터를 찾기 위한 인덱스 자료구조 

IVF은 양자화(Quantization) 알고리즘 이라고도 불리는데, 여기서 양자화란 컴퓨터에서 처리하기 어려운 거대한 데이터를 압축 표현하여 성능을 높이는 방법을 말함

예로 float32 데이터 타입을 int8 로 압축할 수 있다면, 크기가 4배로 줄어드는 효과가 있음

![image](https://github.com/user-attachments/assets/b7b3bf0f-7c92-4414-ac33-191b9a120c24)

</details>

벡터 데이터베이스는 데이터 관리, 내결함성, 인증 및 액세스 제어, 쿼리 엔진과 같은 추가 기능을 제공

- **내결함성 : 시스템의 일부 구성 요소가 작동하지 않더라도 계속 작동할 수 있는 기능**

# 2. Vector DB의 종류
Vector DB의 종류를 알아보기 쉽게 한 테이블로 정리해 보면 다음과 같다. 

제시된 Vector DB들의 강점은 **자체적인 알고리즘으로 색인(index)과 유사한 벡터들을 검색**을 해준다는 점!

또한 일부 Vector DB는 GPU를 바탕으로 검색을 해주는 경우도 존재 
(단, GPU는 Data 건수마다 제한 조건이 존재하며 상이함)

![image](https://github.com/user-attachments/assets/d5c03086-abbc-4786-b3b5-2784d5ab69b3)

⇒ Milvus는 FAISS를 여러모로 업그레이드 한 Vector DB

<details>
<summary>번외 : FAISS</summary> 

https://devocean.sk.com/blog/techBoardDetail.do?ID=165867&boardType=techBlog

https://dajeblog.co.kr/16-faiss%EC%97%90-%EB%8C%80%ED%95%9C-%EB%AA%A8%EB%93%A0-%EA%B2%83/

FAISS는 고차원 벡터 데이터의 유사성 검색을 빠르게 수행하는 도구(=라이브러리)

다양한 인덱스 유형, GPU 지원, 사용자 정의 인덱스 등을 제공하며, 딥러닝 분야에서 이미지, 텍스트, 음성 등의 검색에 널리 사용 됨

![image](https://github.com/user-attachments/assets/1faba2f7-d609-45ac-952a-15f6b1537347)


**인덱스란?**

**FAISS의 핵심 개념은 인덱스(index) 생성임!**

인덱스는 벡터 데이터의 구조를 나타내는 메타데이터로 볼 수 있으며, 이를 통해 효율적인 검색이 가능 

FAISS는 먼저 데이터를 양자화하여 인덱스를 생성하고, 이후 이 인덱스를 사용하여 유사성 검색을 수행

이 과정에서 FAISS는 복잡한 벡터 공간을 작은 ‘클러스터’로 분할하는데, 각 클러스터는 그 안의 벡터들이 서로 유사하다는 점에서 차별성을 가짐 
클러스터링은 원본 벡터 공간을 더 작고, 이해하기 쉽고, 계산하기 편한 공간으로 변환하는 역할을 수행

이렇게 생성된 클러스터는 원래의 대량 데이터 대신 사용될 수 있으며, 각 클러스터는 원본 데이터의 ‘대표’ 또는 ‘중심’을 나타내게 됨 (=centroid)

## 실제로 어떻게 사용하나?

FAISS를 사용하려면 먼저 필요한 벡터 데이터를 로드하고, 이를 FAISS 인덱스에 추가하는 과정을 거침 

그 다음으로는 인덱스를 학습 시키고, 이를 사용하여 유사성 검색을 수행

FAISS 인덱스를 학습시키는 과정은 크게 두 단계로 나눌 수 있음 

먼저, 전체 벡터 데이터셋에 대한 **‘전역’ 클러스터링**을 수행
이렇게 생성된 전역 클러스터는 벡터 공간을 광범위하게 커버할 수 있음 **(coarse-grained)**

그 다음 단계에서는 각 전역 클러스터 내에서 추가적인 **‘로컬’ 클러스터링**을 수행하여, 
클러스터의 수를 늘리고 벡터 공간을 더욱 세밀하게 나눔 **(fine-grained)**

**⇒ 위의 과정은 예로 들면 우선 개라는 카테고리로 전역 클러스터링을 수행하고
개 중에서도 종류 별로 클러스터링(불독, 치와와 …) 하는 것을 로컬 클러스터링이라 이해**

검색을 수행할 때는 쿼리 벡터를 입력으로 받아서, 이와 가장 유사한 벡터들을 인덱스에서 찾아 반환합니다. 이는 인덱스 내의 각 클러스터에 대해 계산되며, 가장 유사도가 높은 클러스터들이 결국 반환 결과로 선택됩니다.

벡터 임베딩을 FAISS 인덱스에 저장하는 방법은 아래와 같다.

1. **벡터 추가**: 벡터 임베딩을 FAISS 인덱스에 추가
2. **인덱스 저장**: 생성된 인덱스를 파일로 저장
3. **인덱스 로드**: 저장된 인덱스를 다시 불러와서 사용

예를 들어, 아래와 같은 코드로 벡터 임베딩을 FAISS 인덱스에 저장하고 나중에 로드 가능
![image](https://github.com/user-attachments/assets/ef7c929a-afd7-415a-b062-db16e4d67e7a)

- FAISS 사용법 기본 예시

그런데 위의 예시는 일회성임 (코드를 실행할 때 마다 Vector DB 초기화)
그렇기 때문에, 실제 데이터 저장은 Mongo DB에 저장하고 FAISS는 유사도 기반 검색 기능만 수행

</details>
